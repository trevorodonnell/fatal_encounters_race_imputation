{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score\n",
    "from tensorflow.keras.layers import Dense, Dropout, GRU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import metrics as tfmet\n",
    "from tensorflow.keras import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at training data shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19628, 273)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating X and y variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = ['Race', 'Unique ID'])\n",
    "y = df['Race']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14721, 271)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating the TFIDF Vectorizer on the text in the description column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvec = TfidfVectorizer(stop_words='english', strip_accents = 'ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tvec = tvec.fit_transform(X_train['description'])\n",
    "X_test_tvec = tvec.transform(X_test['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a dataframe from a the dense array of our vectorized text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tvec_df = pd.DataFrame(X_train_tvec.todense(),columns=tvec.get_feature_names())\n",
    "X_test_tvec_df = pd.DataFrame(X_test_tvec.todense(),columns=tvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining shape of TFIDF dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14721, 23914)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tvec_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the ten most common terms from the description text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_tvec_df.sum().sort_values(ascending=False).head(10).plot(kind='barh');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg1 = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting logisitic regression model on vectorized text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/trevorodonnell/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg1.fit(X_train_tvec_df, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining training accuracy scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8056517899599211"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg1.score(X_train_tvec_df, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining testing accuracy scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6472386386794375"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg1.score(X_test_tvec_df, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a dataframe to examine TFIDF coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = pd.concat([pd.DataFrame(X_train_tvec_df.columns), \n",
    "                          pd.DataFrame(np.transpose(logreg1.coef_))],\n",
    "                          axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_column_uniquify(df):\n",
    "    df_columns = df.columns\n",
    "    new_columns = []\n",
    "    for item in df_columns:\n",
    "        counter = 0\n",
    "        newitem = item\n",
    "        while newitem in new_columns:\n",
    "            counter += 1\n",
    "            newitem = \"{}_{}\".format(item, counter)\n",
    "        new_columns.append(newitem)\n",
    "    df.columns = new_columns\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = df_column_uniquify(coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = coefficients.rename(columns={0 : \"word\", \"0_1\" : \"coefficient_value\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most predictive terms in the incident description "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>coefficient_value</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3272</th>\n",
       "      <td>brown</td>\n",
       "      <td>2.478846</td>\n",
       "      <td>-0.387245</td>\n",
       "      <td>-0.173454</td>\n",
       "      <td>-1.865486</td>\n",
       "      <td>-0.039341</td>\n",
       "      <td>-0.013320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11450</th>\n",
       "      <td>johnson</td>\n",
       "      <td>2.402715</td>\n",
       "      <td>-0.344387</td>\n",
       "      <td>0.079671</td>\n",
       "      <td>-1.689135</td>\n",
       "      <td>-0.043688</td>\n",
       "      <td>-0.405176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23399</th>\n",
       "      <td>williams</td>\n",
       "      <td>2.358154</td>\n",
       "      <td>0.108565</td>\n",
       "      <td>-0.952017</td>\n",
       "      <td>-1.522509</td>\n",
       "      <td>-0.048829</td>\n",
       "      <td>0.056636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11096</th>\n",
       "      <td>jackson</td>\n",
       "      <td>2.187326</td>\n",
       "      <td>-0.436050</td>\n",
       "      <td>-1.092002</td>\n",
       "      <td>-0.769307</td>\n",
       "      <td>-0.032234</td>\n",
       "      <td>0.142267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23067</th>\n",
       "      <td>washington</td>\n",
       "      <td>2.114714</td>\n",
       "      <td>-0.219752</td>\n",
       "      <td>-0.882499</td>\n",
       "      <td>-0.839837</td>\n",
       "      <td>-0.015278</td>\n",
       "      <td>-0.157348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5797</th>\n",
       "      <td>davis</td>\n",
       "      <td>2.113919</td>\n",
       "      <td>-0.255150</td>\n",
       "      <td>-0.492507</td>\n",
       "      <td>-1.391643</td>\n",
       "      <td>-0.034147</td>\n",
       "      <td>0.059528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18413</th>\n",
       "      <td>rodriguez</td>\n",
       "      <td>-2.084456</td>\n",
       "      <td>0.219770</td>\n",
       "      <td>-1.929307</td>\n",
       "      <td>3.928422</td>\n",
       "      <td>-0.027530</td>\n",
       "      <td>-0.106899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13698</th>\n",
       "      <td>martinez</td>\n",
       "      <td>-2.048479</td>\n",
       "      <td>-0.317666</td>\n",
       "      <td>-1.960855</td>\n",
       "      <td>4.127501</td>\n",
       "      <td>-0.023740</td>\n",
       "      <td>0.223240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18368</th>\n",
       "      <td>robinson</td>\n",
       "      <td>2.000967</td>\n",
       "      <td>-0.254480</td>\n",
       "      <td>-0.788286</td>\n",
       "      <td>-0.977471</td>\n",
       "      <td>-0.017452</td>\n",
       "      <td>0.036722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11476</th>\n",
       "      <td>jones</td>\n",
       "      <td>1.972671</td>\n",
       "      <td>-0.504982</td>\n",
       "      <td>-0.090492</td>\n",
       "      <td>-1.229083</td>\n",
       "      <td>-0.039272</td>\n",
       "      <td>-0.108843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word  coefficient_value         1         2         3         4  \\\n",
       "3272        brown           2.478846 -0.387245 -0.173454 -1.865486 -0.039341   \n",
       "11450     johnson           2.402715 -0.344387  0.079671 -1.689135 -0.043688   \n",
       "23399    williams           2.358154  0.108565 -0.952017 -1.522509 -0.048829   \n",
       "11096     jackson           2.187326 -0.436050 -1.092002 -0.769307 -0.032234   \n",
       "23067  washington           2.114714 -0.219752 -0.882499 -0.839837 -0.015278   \n",
       "5797        davis           2.113919 -0.255150 -0.492507 -1.391643 -0.034147   \n",
       "18413   rodriguez          -2.084456  0.219770 -1.929307  3.928422 -0.027530   \n",
       "13698    martinez          -2.048479 -0.317666 -1.960855  4.127501 -0.023740   \n",
       "18368    robinson           2.000967 -0.254480 -0.788286 -0.977471 -0.017452   \n",
       "11476       jones           1.972671 -0.504982 -0.090492 -1.229083 -0.039272   \n",
       "\n",
       "              5  \n",
       "3272  -0.013320  \n",
       "11450 -0.405176  \n",
       "23399  0.056636  \n",
       "11096  0.142267  \n",
       "23067 -0.157348  \n",
       "5797   0.059528  \n",
       "18413 -0.106899  \n",
       "13698  0.223240  \n",
       "18368  0.036722  \n",
       "11476 -0.108843  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefficients.sort_values(by='coefficient_value', key=abs, ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least predictive terms in incident description "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>coefficient_value</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19160</th>\n",
       "      <td>screamed</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.052742</td>\n",
       "      <td>0.355661</td>\n",
       "      <td>-0.267921</td>\n",
       "      <td>-0.003307</td>\n",
       "      <td>-0.031675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11363</th>\n",
       "      <td>jerrick</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>-0.004929</td>\n",
       "      <td>0.059877</td>\n",
       "      <td>-0.048641</td>\n",
       "      <td>-0.000442</td>\n",
       "      <td>-0.005836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18319</th>\n",
       "      <td>roach</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>-0.030114</td>\n",
       "      <td>0.214408</td>\n",
       "      <td>-0.161714</td>\n",
       "      <td>-0.001786</td>\n",
       "      <td>-0.020752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>aiming</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>-0.057346</td>\n",
       "      <td>0.469755</td>\n",
       "      <td>-0.365142</td>\n",
       "      <td>-0.003941</td>\n",
       "      <td>-0.043394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12423</th>\n",
       "      <td>lapsed</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>-0.015204</td>\n",
       "      <td>0.135034</td>\n",
       "      <td>-0.107975</td>\n",
       "      <td>-0.001162</td>\n",
       "      <td>-0.010834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6214</th>\n",
       "      <td>describes</td>\n",
       "      <td>-0.000143</td>\n",
       "      <td>-0.019704</td>\n",
       "      <td>0.148980</td>\n",
       "      <td>-0.113734</td>\n",
       "      <td>-0.001268</td>\n",
       "      <td>-0.014131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15914</th>\n",
       "      <td>oxycontin</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>-0.009403</td>\n",
       "      <td>0.078160</td>\n",
       "      <td>-0.062028</td>\n",
       "      <td>-0.000725</td>\n",
       "      <td>-0.006158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16070</th>\n",
       "      <td>paranoid</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.082620</td>\n",
       "      <td>0.340388</td>\n",
       "      <td>-0.371875</td>\n",
       "      <td>-0.004678</td>\n",
       "      <td>-0.046656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>28</td>\n",
       "      <td>-0.000219</td>\n",
       "      <td>0.628416</td>\n",
       "      <td>0.268474</td>\n",
       "      <td>-0.726482</td>\n",
       "      <td>-0.023905</td>\n",
       "      <td>-0.146283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7991</th>\n",
       "      <td>fell</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>-0.174066</td>\n",
       "      <td>-0.169373</td>\n",
       "      <td>0.328226</td>\n",
       "      <td>0.081018</td>\n",
       "      <td>-0.066025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  coefficient_value         1         2         3         4  \\\n",
       "19160   screamed          -0.000016 -0.052742  0.355661 -0.267921 -0.003307   \n",
       "11363    jerrick          -0.000029 -0.004929  0.059877 -0.048641 -0.000442   \n",
       "18319      roach          -0.000041 -0.030114  0.214408 -0.161714 -0.001786   \n",
       "929       aiming           0.000067 -0.057346  0.469755 -0.365142 -0.003941   \n",
       "12423     lapsed           0.000141 -0.015204  0.135034 -0.107975 -0.001162   \n",
       "6214   describes          -0.000143 -0.019704  0.148980 -0.113734 -0.001268   \n",
       "15914  oxycontin           0.000154 -0.009403  0.078160 -0.062028 -0.000725   \n",
       "16070   paranoid           0.000201  0.082620  0.340388 -0.371875 -0.004678   \n",
       "287           28          -0.000219  0.628416  0.268474 -0.726482 -0.023905   \n",
       "7991        fell           0.000221 -0.174066 -0.169373  0.328226  0.081018   \n",
       "\n",
       "              5  \n",
       "19160 -0.031675  \n",
       "11363 -0.005836  \n",
       "18319 -0.020752  \n",
       "929   -0.043394  \n",
       "12423 -0.010834  \n",
       "6214  -0.014131  \n",
       "15914 -0.006158  \n",
       "16070 -0.046656  \n",
       "287   -0.146283  \n",
       "7991  -0.066025  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefficients.sort_values(by='coefficient_value', key=abs, ascending = True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF & all other features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see if we can improve the test accuracy score of the model by adding the processed text as features in addition to all of our numeric features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reseting indices of processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tvec_df.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tvec_df.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping original description column from training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns = ['description'])\n",
    "X_test = X_test.drop(columns = ['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.reset_index(inplace = True)\n",
    "X_test.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating the vectorized text data with the numerical features for training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat((X_train, X_train_tvec_df), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the shape and content formatting of new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14721, 24186)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Age</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week_of_year</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>pop2000</th>\n",
       "      <th>pop2010</th>\n",
       "      <th>...</th>\n",
       "      <th>zuni</th>\n",
       "      <th>zuniga</th>\n",
       "      <th>zunker</th>\n",
       "      <th>zurita</th>\n",
       "      <th>zuschin</th>\n",
       "      <th>zutavern</th>\n",
       "      <th>zwolinski</th>\n",
       "      <th>zx1</th>\n",
       "      <th>zylstra</th>\n",
       "      <th>zyonne</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1452</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>2229379.0</td>\n",
       "      <td>2230722</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>775</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9519338.0</td>\n",
       "      <td>9818605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2109</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>347.0</td>\n",
       "      <td>196533.0</td>\n",
       "      <td>231236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13270</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>312090.0</td>\n",
       "      <td>349497</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6612</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>153406.0</td>\n",
       "      <td>221339</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24186 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   Age    year  month  week_of_year  day_of_month  day_of_week  \\\n",
       "0   1452  19.0  2004.0    7.0          30.0          29.0          3.0   \n",
       "1    775  20.0  2003.0    1.0           2.0          12.0          6.0   \n",
       "2   2109  21.0  2005.0   12.0          50.0          13.0          1.0   \n",
       "3  13270  43.0  2017.0    5.0          21.0          21.0          6.0   \n",
       "4   6612  44.0  2012.0    8.0          34.0          19.0          6.0   \n",
       "\n",
       "   day_of_year    pop2000  pop2010  ...  zuni  zuniga  zunker  zurita  \\\n",
       "0        211.0  2229379.0  2230722  ...   0.0     0.0     0.0     0.0   \n",
       "1         12.0  9519338.0  9818605  ...   0.0     0.0     0.0     0.0   \n",
       "2        347.0   196533.0   231236  ...   0.0     0.0     0.0     0.0   \n",
       "3        141.0   312090.0   349497  ...   0.0     0.0     0.0     0.0   \n",
       "4        232.0   153406.0   221339  ...   0.0     0.0     0.0     0.0   \n",
       "\n",
       "   zuschin  zutavern  zwolinski  zx1  zylstra  zyonne  \n",
       "0      0.0       0.0        0.0  0.0      0.0     0.0  \n",
       "1      0.0       0.0        0.0  0.0      0.0     0.0  \n",
       "2      0.0       0.0        0.0  0.0      0.0     0.0  \n",
       "3      0.0       0.0        0.0  0.0      0.0     0.0  \n",
       "4      0.0       0.0        0.0  0.0      0.0     0.0  \n",
       "\n",
       "[5 rows x 24186 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating the vectorized text data with the numerical features for testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.concat((X_test, X_test_tvec_df), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the shape and content formatting of new dataframe, as well as null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4907, 24186)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Age</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week_of_year</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>pop2000</th>\n",
       "      <th>pop2010</th>\n",
       "      <th>...</th>\n",
       "      <th>zuni</th>\n",
       "      <th>zuniga</th>\n",
       "      <th>zunker</th>\n",
       "      <th>zurita</th>\n",
       "      <th>zuschin</th>\n",
       "      <th>zutavern</th>\n",
       "      <th>zwolinski</th>\n",
       "      <th>zx1</th>\n",
       "      <th>zylstra</th>\n",
       "      <th>zyonne</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15542</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>9519338.0</td>\n",
       "      <td>9818605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4739</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>9519338.0</td>\n",
       "      <td>9818605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2221</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2813833.0</td>\n",
       "      <td>3095313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6444</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>1545387.0</td>\n",
       "      <td>2189641</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9097</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>163256.0</td>\n",
       "      <td>177223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24186 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   Age    year  month  week_of_year  day_of_month  day_of_week  \\\n",
       "0  15542  29.0  2018.0    5.0          21.0          30.0          2.0   \n",
       "1   4739  27.0  2010.0    5.0          21.0          26.0          2.0   \n",
       "2   2221  75.0  2006.0    3.0          10.0           6.0          0.0   \n",
       "3   6444  31.0  2012.0    7.0          27.0           1.0          6.0   \n",
       "4   9097  33.0  2014.0    7.0          30.0          27.0          6.0   \n",
       "\n",
       "   day_of_year    pop2000  pop2010  ...  zuni  zuniga  zunker  zurita  \\\n",
       "0        150.0  9519338.0  9818605  ...   0.0     0.0     0.0     0.0   \n",
       "1        146.0  9519338.0  9818605  ...   0.0     0.0     0.0     0.0   \n",
       "2         65.0  2813833.0  3095313  ...   0.0     0.0     0.0     0.0   \n",
       "3        183.0  1545387.0  2189641  ...   0.0     0.0     0.0     0.0   \n",
       "4        208.0   163256.0   177223  ...   0.0     0.0     0.0     0.0   \n",
       "\n",
       "   zuschin  zutavern  zwolinski  zx1  zylstra  zyonne  \n",
       "0      0.0       0.0        0.0  0.0      0.0     0.0  \n",
       "1      0.0       0.0        0.0  0.0      0.0     0.0  \n",
       "2      0.0       0.0        0.0  0.0      0.0     0.0  \n",
       "3      0.0       0.0        0.0  0.0      0.0     0.0  \n",
       "4      0.0       0.0        0.0  0.0      0.0     0.0  \n",
       "\n",
       "[5 rows x 24186 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling data before modeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xsc_train = sc.fit_transform(X_train)\n",
    "Xsc_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(max_iter=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting logistic regression on 24,186 features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=50000)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(Xsc_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining training and test scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9994565586576999"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(Xsc_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7248828204605665"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(Xsc_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
